{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this competition is to predict the hourly rain gauge total. The evaluation metrics for this competition is Mean Absolute Error which is written into the file submission.csv that consists of the columns - id and Expected. Methods used in the field of deep learning -  LSTM was implemented on the dataset. LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the train and test dataset are:\n",
    "\n",
    "Id:  A unique number for the set of observations over an hour at a gauge.\n",
    "minutes_past:  For each set of radar observations, the minutes past the top of the hour that the radar observations were carried out.  Radar observations are snapshots at that point in time.\n",
    "radardist_km:  Distance of gauge from the radar whose observations are being reported.\n",
    "Ref:  Radar reflectivity in km\n",
    "Ref_5x5_10th:   10th percentile of reflectivity values in 5x5 neighborhood around the gauge.\n",
    "Ref_5x5_50th:   50th percentile\n",
    "Ref_5x5_90th:   90th percentile\n",
    "RefComposite:  Maximum reflectivity in the vertical column above gauge.  In dBZ.\n",
    "RefComposite_5x5_10th\n",
    "RefComposite_5x5_50th\n",
    "RefComposite_5x5_90th\n",
    "RhoHV:  Correlation coefficient (unitless)\n",
    "RhoHV_5x5_10th\n",
    "RhoHV_5x5_50th\n",
    "RhoHV_5x5_90th\n",
    "Zdr:    Differential reflectivity in dB\n",
    "Zdr_5x5_10th\n",
    "Zdr_5x5_50th\n",
    "Zdr_5x5_90th\n",
    "Kdp:  Specific differential phase (deg/km)\n",
    "Kdp_5x5_10th\n",
    "Kdp_5x5_50th\n",
    "Kdp_5x5_90th\n",
    "Expected:  Actual gauge observation in mm at the end of the hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "N_FEATURES = 22\n",
    "\n",
    "# taken from http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/\n",
    "THRESHOLD = 73 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importimg train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reduce memory consumption\n",
    "train_df[train_df.columns[1:]] = train_df[train_df.columns[1:]].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train dataset consists of 13765201 rows and 24 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13765201, 24)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values if any in the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                       False\n",
       "minutes_past             False\n",
       "radardist_km             False\n",
       "Ref                      False\n",
       "Ref_5x5_10th             False\n",
       "Ref_5x5_50th             False\n",
       "Ref_5x5_90th             False\n",
       "RefComposite             False\n",
       "RefComposite_5x5_10th    False\n",
       "RefComposite_5x5_50th    False\n",
       "RefComposite_5x5_90th    False\n",
       "RhoHV                    False\n",
       "RhoHV_5x5_10th           False\n",
       "RhoHV_5x5_50th           False\n",
       "RhoHV_5x5_90th           False\n",
       "Zdr                      False\n",
       "Zdr_5x5_10th             False\n",
       "Zdr_5x5_50th             False\n",
       "Zdr_5x5_90th             False\n",
       "Kdp                      False\n",
       "Kdp_5x5_10th             False\n",
       "Kdp_5x5_50th             False\n",
       "Kdp_5x5_90th             False\n",
       "Expected                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross checking for null values\n",
    "train_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all the entries from the dataset with the Ref column having  null values. The dataset further consists of 9125329 entries with 24 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8926102, 24)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_ids = set(train_df.loc[train_df['Ref'].notna(), 'Id'])\n",
    "train_df = train_df[train_df['Id'].isin(good_ids)]\n",
    "train_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling null values by replacing null values with 0 in all the columns with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>minutes_past</th>\n",
       "      <th>radardist_km</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Ref_5x5_10th</th>\n",
       "      <th>Ref_5x5_50th</th>\n",
       "      <th>Ref_5x5_90th</th>\n",
       "      <th>RefComposite</th>\n",
       "      <th>RefComposite_5x5_10th</th>\n",
       "      <th>RefComposite_5x5_50th</th>\n",
       "      <th>...</th>\n",
       "      <th>RhoHV_5x5_90th</th>\n",
       "      <th>Zdr</th>\n",
       "      <th>Zdr_5x5_10th</th>\n",
       "      <th>Zdr_5x5_50th</th>\n",
       "      <th>Zdr_5x5_90th</th>\n",
       "      <th>Kdp</th>\n",
       "      <th>Kdp_5x5_10th</th>\n",
       "      <th>Kdp_5x5_50th</th>\n",
       "      <th>Kdp_5x5_90th</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>1.059998</td>\n",
       "      <td>-1.410004</td>\n",
       "      <td>-0.350006</td>\n",
       "      <td>1.059998</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>31.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>28.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.409988</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>20.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>23.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001667</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.349991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.350006</td>\n",
       "      <td>1.759995</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.349991</td>\n",
       "      <td>-1.059998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.059998</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>-0.350006</td>\n",
       "      <td>-1.059998</td>\n",
       "      <td>-0.350006</td>\n",
       "      <td>1.759995</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  minutes_past  radardist_km   Ref  Ref_5x5_10th  Ref_5x5_50th  \\\n",
       "0   2           1.0           2.0   9.0           5.0           7.5   \n",
       "1   2           6.0           2.0  26.5          22.5          25.5   \n",
       "2   2          11.0           2.0  21.5          15.5          20.5   \n",
       "3   2          16.0           2.0  18.0          14.0          17.5   \n",
       "4   2          21.0           2.0  24.5          16.5          21.0   \n",
       "\n",
       "   Ref_5x5_90th  RefComposite  RefComposite_5x5_10th  RefComposite_5x5_50th  \\\n",
       "0          10.5          15.0                   10.5                   16.5   \n",
       "1          31.5          26.5                   26.5                   28.5   \n",
       "2          25.0          26.5                   23.5                   25.0   \n",
       "3          21.0          20.5                   18.0                   20.5   \n",
       "4          24.5          24.5                   21.0                   24.0   \n",
       "\n",
       "     ...     RhoHV_5x5_90th     Zdr  Zdr_5x5_10th  Zdr_5x5_50th  Zdr_5x5_90th  \\\n",
       "0    ...           0.998333  0.3750       -0.1250        0.3125        0.8750   \n",
       "1    ...           1.005000  0.0625       -0.1875        0.2500        0.6875   \n",
       "2    ...           1.001667  0.3125       -0.0625        0.3125        0.6250   \n",
       "3    ...           1.001667  0.2500        0.1250        0.3750        0.6875   \n",
       "4    ...           0.998333  0.2500        0.0625        0.1875        0.5625   \n",
       "\n",
       "        Kdp  Kdp_5x5_10th  Kdp_5x5_50th  Kdp_5x5_90th  Expected  \n",
       "0  1.059998     -1.410004     -0.350006      1.059998  1.016001  \n",
       "1  0.000000      0.000000      0.000000      1.409988  1.016001  \n",
       "2  0.349991      0.000000     -0.350006      1.759995  1.016001  \n",
       "3  0.349991     -1.059998      0.000000      1.059998  1.016001  \n",
       "4 -0.350006     -1.059998     -0.350006      1.759995  1.016001  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.fillna(0.0, inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing outliers from the dataset by taking the value of threshold as 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-656d324aed7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Expected'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mTHRESHOLD\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df = train_df[train_df['Expected'] < THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8926102, 24)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping the train dataset by Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_groups = train_df.groupby(\"Id\")\n",
    "train_size = len(train_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LEN = train_groups.size().max()\n",
    "MAX_SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((714838, 19, 22), (714838,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.zeros((train_size, MAX_SEQ_LEN, N_FEATURES), dtype=np.float32)\n",
    "y_train = np.zeros(train_size, dtype=np.float32)\n",
    "\n",
    "i = 0\n",
    "for _, group in train_groups:\n",
    "    X = group.values\n",
    "    seq_len = X.shape[0]\n",
    "    X_train[i,:seq_len,:] = X[:,1:23]\n",
    "    y_train[i] = X[0,23]\n",
    "    i += 1\n",
    "    del X\n",
    "    \n",
    "del train_groups\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing test datasheet and handling NaN values by replacing it with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df[test_df.columns[1:]] = test_df[test_df.columns[1:]].astype(np.float32)\n",
    "test_ids = test_df['Id'].unique()\n",
    "\n",
    "# Convert all NaNs to zero\n",
    "test_df = test_df.fillna(0.0)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing X_test values from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_groups = test_df.groupby(\"Id\")\n",
    "test_size = len(test_groups)\n",
    "\n",
    "X_test = np.zeros((test_size, MAX_SEQ_LEN, N_FEATURES), dtype=np.float32)\n",
    "\n",
    "i = 0\n",
    "for _, group in test_groups:\n",
    "    X = group.values\n",
    "    seq_len = X.shape[0]\n",
    "    X_test[i,:seq_len,:] = X[:,1:23]\n",
    "    i += 1\n",
    "    del X\n",
    "    \n",
    "del test_groups\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence in sequence prediction problems. This is a behavior required in complex problem domains like machine translation, speech recognition, and more. LSTMs are a complex area of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the required libraries for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-be2391e6c6e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m from keras.layers import (\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mAveragePooling1D\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    LSTM,\n",
    "    AveragePooling1D,\n",
    "    TimeDistributed,\n",
    "    Flatten,\n",
    "    Bidirectional,\n",
    "    Dropout\n",
    ")\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have implemented two call back functions here early_stopping and reduce_lr. Callbacks are functions that can be applied at certain stages of the training process, such as at the end of each epoch. Specifically, in our solution, we included EarlyStopping(monitor='val_loss', patience=5) to define that we wanted to monitor the test (validation) loss at each epoch and after the test loss has not improved after 5 epochs, training is interrupted. However, since we set patience=5, we won’t get the best model, but the model five epochs after the best model. \n",
    "\n",
    "Also using Reduce learning rate when a metric has stopped improving.\n",
    "\n",
    "Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n",
    "1. monitor: quantity to be monitored.\n",
    "2. factor: factor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "3. patience: number of epochs with no improvement after which learning rate will be reduced.\n",
    "4. min_delta: threshold for measuring the new optimum, to only focus on significant changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024 #Training batch size at a time\n",
    "N_EPOCHS = 4 #total number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_deep(shape=(19, 22)):\n",
    "    inp = Input(shape)\n",
    "    x = Dense(16)(inp)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = TimeDistributed(Dense(64))(x)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    x = TimeDistributed(Dense(1))(x)\n",
    "    x = AveragePooling1D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1)(x)\n",
    "\n",
    "    model = Model(inp, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configures the model for training with optimizer and loss.\n",
    "The loss value that will be minimized by the model will then be the sum of all individual losses.\n",
    "optimizer - adam optimizer a methos for stochastic optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_deep((19,22))\n",
    "model.compile(optimizer='adam', loss='mae',)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model with batch size of 1024 at a time with 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, \n",
    "            batch_size=BATCH_SIZE, epochs=N_EPOCHS, \n",
    "            validation_split=0.2, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "sample_solution = pd.DataFrame({'Id': test_ids, 'Expected': y_pred.reshape(-1)})\n",
    "sample_solution.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the soluion to submission.csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Performed data cleaning by checking for null values and replacing them with placeholder values along with EDA.\n",
    "2. Added necessary comments, required observations after every results and explanations to the code.\n",
    "3. Changed the values of epochs and patience to check if the model is best trained with minimum loss, tweaked the \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/\n",
    "2. https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0\n",
    "3. https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/\n",
    "4. https://www.kaggle.com/ilya16/lstm-models\n",
    "5. http://www.easy-tensorflow.com/tf-tutorials/recurrent-neural-networks/bidirectional-rnn-for-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LICENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019, Chaitanya Prasanna Kumar\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
